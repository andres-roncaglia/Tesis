---
title: "Tesis"
format: pdf
echo: False
warning: False
---

# Carga de datos y librerias

```{python}
# CARGA DE LIBRERIAS ------------------

# Para el manejo de estructuras de datos
import pandas as pd
import numpy as np

# Para dar formato fecha
from datetime import datetime

# Para realizar consultas a la base de datos
import urllib.parse
import requests

# Para graficos
import matplotlib.pyplot as plt
import seaborn as sns

# Para medir el tiempo que tarda en ajustar los modelos
import time

# Cargamos funciones
from Funciones import get_api_call, interval_score, plot_forecast, save_env, load_env
from tuner_fun import Tuner

# # Para los modelos de SKtime
# from sktime.forecasting.base import ForecastingHorizon
# from sktime.forecasting.arima import AutoARIMA
# from sktime.performance_metrics.forecasting import mean_absolute_percentage_error
```

```{python}
# Cargamos el ambiente

globals().update(load_env('Ambiente/resultados.pkl'))
```

```{python}
# Definimos una semilla
seed = 11072001
```


```{python}
# Llamada a la API y carga de datos

api_call = get_api_call(["364.3_LITORAL_GAGAS__11"], start_date="2016-01")

json = requests.get(api_call).json()

datos = pd.DataFrame(json['data'], columns = ['fecha', 'consumo'])

datos['fecha'] = pd.to_datetime(datos['fecha'], format='%Y-%m-%d')

datos.columns = ['ds', 'y']
```


```{python}
# datos = pd.read_csv(filepath_or_buffer= 'Datos/exportaciones-actividad-saldocomercial-rangos-exportacion-empresa-exportadora-mensual.csv')

# datos = datos[['indice_tiempo','litoral_gas']]

# datos.columns = ['fecha', 'consumo']

# datos['fecha'] = pd.to_datetime(datos['fecha'], format='%Y-%m-%d')

# datos.dropna(inplace=True)
```

```{python}
# Tabla con los primeros y ultimos datos
print(datos.head(3),datos.tail(3))

# Grafico los datos
plt.plot(datos['ds'], datos['y'], marker = '.')
plt.title('Consumo de gas natural')
plt.xlabel('Año')
plt.ylabel('Consumo (millones de metros cúbicos)')
plt.show()

```


```{python}
# Opciones de pronóstico

# Largo del pronóstico

long_pred = 12

# Nivel de significación del intervalo de predicción

alpha = 0.2

```

```{python}
# Creamos un dataframe donde vamos a guardar todos los resultados
metricas = pd.DataFrame(columns=(['Modelo', 'MAPE', 'Interval Score', 'Tiempo']))
```

# MODELOS

## Tradicionales

```{python}
# Dividimos el conjunto de datos que queremos pronosticar
corte = len(datos)-long_pred

datos.columns = ['ds', 'y']

datos_train = datos[:corte]
datos_test = datos[corte:]
```

```{python}
# ARIMA CON FUNCION

# Definimos los parametros a tunear
params = {
    "start_p" : 0, "max_p" : 3,
    "start_q" : 0, "max_q" : 3,
    "start_P" : 0, "max_P" : 3,
    "start_Q" : 0, "max_Q" : 3,
    "max_d":2, "max_D": 2,
    "random_state" : seed
}

# Tuneamos los parametros y ajustamos el modelo
resultados_arima = Tuner(forecaster_fun= 'ARIMA', datos=datos, parametros=params, alpha= alpha, long_pred = long_pred)

# Graficamos el pronostico
plot_forecast(data = datos, forecast = resultados_arima['pred'], color = 'green', label = 'ARIMA')

# Guardamos las metricas
metricas.loc[len(metricas)] = ['XGBoost', resultados_xgb['mape'], resultados_xgb['score'], resultados_xgb['tiempo']]
```

## Machine learning

```{python}
# XGBoost (https://cloud.google.com/python/docs/reference/bigframes/latest/bigframes.ml.ensemble.XGBRegressor)(https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)

# Definimos los parametros a tunear
params = {
    "tree_method": ['exact'],
    "random_state": [seed],
    "max_leaves": [2,4,8,16],
    "max_depth": [2,3,4,5],
    "learning_rate": [0.1, 0.2, 0.3],
    "n_estimators": [20, 50, 100, 150]

}

# Tuneamos los parametros y ajustamos el modelo
resultados_xgb = Tuner(forecaster_fun= 'XGBoost', datos=datos, parametros=params, alpha= alpha, long_pred = long_pred)

# Graficamos el pronostico
plot_forecast(data = datos, forecast = resultados_xgb['pred'], color = 'green', label = 'XGBoost')

# Guardamos las metricas
metricas.loc[len(metricas)] = ['XGBoost', resultados_xgb['mape'], resultados_xgb['score'], resultados_xgb['tiempo']]
```

```{python}
# LightGBM (https://lightgbm.readthedocs.io/en/latest/Parameters.html)

# Definimos los parametros a tunear
params = {
    "random_state": [seed],
    "max_depth": [2,3,4,5],
    "learning_rate": [0.1, 0.2, 0.3],
    "n_estimators": [20, 50, 100, 150],
    'num_leaves' : [5, 10, 20, 30, 50],
    # 'extra_trees' : ['true', 'false']
}

# Tuneamos los parametros y ajustamos el modelo
resultados_lgbm = Tuner(forecaster_fun= 'LightGBM', datos=datos, parametros=params, alpha= alpha, long_pred = long_pred)

# Graficamos el pronostico
plot_forecast(data = datos, forecast = resultados_lgbm['pred'], color = 'green', label = 'LightGBM')

# Guardamos las metricas
metricas.loc[len(metricas)] = ['LightGBM', resultados_lgbm['mape'], resultados_lgbm['score'], resultados_lgbm['tiempo']]
```

## Deep learning

```{python}
# LSTM (https://nixtlaverse.nixtla.io/neuralforecast/models.lstm.html)

# Definimos los parametros a tunear
parametros = {
    'max_steps' : [50, 100, 200, 500],
    'random_seed' : [seed],
    'encoder_n_layers' : [1,2,3],
    'decoder_layers' : [1,2,3]
    }

# Tuneamos los parametros y ajustamos el modelo
resultados_lstm = Tuner(forecaster_fun= 'LSTM', datos=datos, parametros= parametros, alpha= alpha, long_pred = long_pred)

# Graficamos el pronostico
plot_forecast(data = datos, forecast = resultados_lstm['pred'], color = 'violet', label = 'LSTM')

# Guardamos las metricas
metricas.loc[len(metricas)] = ['LSTM', resultados_lstm['mape'], resultados_lstm['score'], resultados_lstm['tiempo']]
```

```{python}
# TIME GPT (https://docs.nixtla.io/docs/capabilities-forecast-forecast)

# Definimos los parametros a tunear
parametros = {
    'finetune_loss' : ['mape'],
    'finetune_steps' : [1,2,5,10,15],
    'finetune_depth' : [1, 2, 3, 5]
    }

# Tuneamos los parametros y ajustamos el modelo
resultados_gpt = Tuner(forecaster_fun= 'TimeGPT', datos=datos, parametros= parametros, alpha= alpha, long_pred = long_pred)

# Graficamos el pronostico
plot_forecast(data = datos, forecast = resultados_gpt['pred'], color = 'violet', label = 'TimeGPT')

# Guardamos las metricas
metricas.loc[len(metricas)] = ['TimeGPT', resultados_gpt['mape'], resultados_gpt['score'], resultados_gpt['tiempo']]

```


```{python}
# Guardamos el ambiente
save_env(env_dict=globals(), filename="Ambiente/resultados.pkl")
```

