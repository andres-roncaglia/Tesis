---
title: "Tesis"
format: pdf
echo: False
warning: False
---

# Carga de datos y librerias

```{python}
# CARGA DE LIBRERIAS ------------------

# Para el manejo de estructuras de datos
import pandas as pd
import numpy as np

# Para dar formato fecha
from datetime import datetime

# Para realizar consultas a la base de datos
import urllib.parse
import requests

# Para graficos
import matplotlib.pyplot as plt
import seaborn as sns

# Para medir el tiempo que tarda en ajustar los modelos
import time

# Cargamos funciones
from Funciones import get_api_call, interval_score, plot_forecast, save_env, load_env
from tuner_fun import Tuner

# Para los modelos de SKtime
from sktime.forecasting.base import ForecastingHorizon
from sktime.forecasting.arima import AutoARIMA
from sktime.performance_metrics.forecasting import mean_absolute_percentage_error
```

```{python}
# Cargamos el ambiente

globals().update(load_env('Ambiente/resultados.pkl'))
```

```{python}
# Definimos una semilla
seed = 11072001
```


```{python}
# Llamada a la API y carga de datos

api_call = get_api_call(["364.3_LITORAL_GAGAS__11"], start_date="2016-01")

json = requests.get(api_call).json()

datos = pd.DataFrame(json['data'], columns = ['fecha', 'consumo'])

datos['fecha'] = pd.to_datetime(datos['fecha'], format='%Y-%m-%d')

datos.columns = ['ds', 'y']
```


```{python}
# datos = pd.read_csv(filepath_or_buffer= 'Datos/exportaciones-actividad-saldocomercial-rangos-exportacion-empresa-exportadora-mensual.csv')

# datos = datos[['indice_tiempo','litoral_gas']]

# datos.columns = ['fecha', 'consumo']

# datos['fecha'] = pd.to_datetime(datos['fecha'], format='%Y-%m-%d')

# datos.dropna(inplace=True)
```

```{python}
# Tabla con los primeros y ultimos datos
print(datos.head(3),datos.tail(3))

# Grafico los datos
plt.plot(datos['ds'], datos['y'], marker = '.')
plt.title('Consumo de gas natural')
plt.xlabel('Año')
plt.ylabel('Consumo (millones de metros cúbicos)')
plt.show()

```


```{python}
# Opciones de pronóstico

# Largo del pronóstico

long_pred = 12

# Nivel de significación del intervalo de predicción

alpha = 0.2

```

```{python}
# Creamos un dataframe donde vamos a guardar todos los resultados
metricas = pd.DataFrame(columns=(['Modelo', 'MAPE', 'Interval Score', 'Tiempo']))
```

# MODELOS

## Tradicionales

```{python}
# Dividimos el conjunto de datos que queremos pronosticar
corte = len(datos)-long_pred

datos.columns = ['ds', 'y']

datos_train = datos[:corte]
datos_test = datos[corte:]
```

```{python}
# AUTOARIMA

# Ajustamos el modelo
timer_comienzo = time.time() # Empiezo a medir cuanto tarda en ajustar

from pmdarima import auto_arima

modelo = auto_arima(datos_train['y'], 
                        start_p = 0, max_p = 3,
                        start_q = 0, max_q = 3,
                        start_P = 0, max_P = 3,
                        start_Q = 0, max_Q = 3,
                        max_d=2, max_D= 2,
                        m = 12,
                        trace = False, 
                        error_action ='ignore',   
                        suppress_warnings = True, 
                        stepwise = True,
                        random_state = seed)

# Obtenemos predicciones
pred, pred_int = modelo.predict(n_periods = long_pred, alpha = alpha/2, return_conf_int=True)
  
timer_final = time.time()
tiempo = timer_final - timer_comienzo

# Guardamos los pronosticos en un dataframe
pred_int = pd.DataFrame(pred_int, columns=['lower', 'upper'])
pred_int.reset_index(drop=True, inplace=True)

pred_arima = pd.concat([
    datos_test['ds'].reset_index(drop=True),
    pred.reset_index(drop=True),
    pred_int['lower'].reset_index(drop=True),
    pred_int['upper'].reset_index(drop=True)
], axis=1)

pred_arima.columns = ['ds', 'pred', 'lower', 'upper']
# Calculamos MAPE
mape = mean_absolute_percentage_error(datos_test['y'], pred_arima['pred'])

# Calculamos Interval Score
score = interval_score(obs=datos_test['y'], lower=pred_arima['lower'], upper=pred_arima['upper'], alpha = alpha)

# Graficamos el pronostico
plot_forecast(data = datos, forecast = pred_arima, color = 'red', label = 'AutoARIMA')

# Guardamos las metricas
metricas.loc[len(metricas)] = ['AutoARIMA', mape, score, tiempo]

resultados_arima = {'pred': pred_arima, 'mape': mape, 'score': score, 'tiempo': tiempo}

```

```{python}
from ngboost import NGBRegressor

# Creamos una copia del dataset
datos_xgb = datos.copy()

# Calculamos las características a usar
datos_xgb['month'] = datos_xgb['ds'].dt.month
datos_xgb['year'] = datos_xgb['ds'].dt.year
datos_xgb["promedio_3_meses"] = datos_xgb["y"].shift(1).rolling(window=3).mean() # Promedio en una ventana de 3 meses
datos_xgb["desvio_3_meses"] = datos_xgb["y"].shift(1).rolling(window=3).std() # Desvio en una ventana de 3 meses
datos_xgb["lag_1"] = datos_xgb["y"].shift(1)
datos_xgb["lag_2"] = datos_xgb["y"].shift(2)
datos_xgb["lag_12"] = datos_xgb["y"].shift(12)

# Dividimos en entrenamiento y testeo
corte = len(datos_xgb)-long_pred

datos_xgb_train = datos_xgb[:corte]
datos_xgb_test = datos_xgb[corte:]

# Extraemos las características
X_train = datos_xgb_train[['month', 'year', 'promedio_3_meses', 'desvio_3_meses', 'lag_1', 'lag_2', 'lag_12']]
X_test = datos_xgb_test[['month', 'year', 'promedio_3_meses', 'desvio_3_meses', 'lag_1', 'lag_2', 'lag_12']]

ngb = NGBRegressor().fit(X_train, datos_xgb_train['y'])
Y_preds = ngb.predict(X_test)
Y_dists = ngb.pred_dist(X_test)

pred_ngb = pd.DataFrame({
    'ds' : datos_test['ds'],
    'pred' : Y_preds,
    'lower' : Y_dists.ppf(alpha/2),
    'upper' : Y_dists.ppf(1-alpha/2),
})

plot_forecast(data = datos, forecast = pred_arima, color = 'red', label = 'NGBoost')
```

## Machine learning

```{python}
# XGBoost (https://cloud.google.com/python/docs/reference/bigframes/latest/bigframes.ml.ensemble.XGBRegressor)(https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)

# Definimos los parametros a tunear
params = {
    "tree_method": ['exact'],
    "random_state": [seed],
    "max_leaves": [2,4,8,16],
    "max_depth": [2,3,4,5],
    "learning_rate": [0.1, 0.2, 0.3],
    "n_estimators": [20, 50, 100, 150]

}

# Tuneamos los parametros y ajustamos el modelo
resultados_xgb = Tuner(forecaster_fun= 'XGBoost', datos=datos, parametros=params, alpha= alpha, long_pred = long_pred)

# Graficamos el pronostico
plot_forecast(data = datos, forecast = resultados_xgb['pred'], color = 'green', label = 'XGBoost')

# Guardamos las metricas
metricas.loc[len(metricas)] = ['XGBoost', resultados_xgb['mape'], resultados_xgb['score'], resultados_xgb['tiempo']]
```

```{python}
# LightGBM (https://lightgbm.readthedocs.io/en/latest/Parameters.html)

# Definimos los parametros a tunear
params = {
    "random_state": [seed],
    "max_depth": [2,3,4,5],
    "learning_rate": [0.1, 0.2, 0.3],
    "n_estimators": [20, 50, 100, 150],
    'num_leaves' : [5, 10, 20, 30, 50],
    # 'extra_trees' : ['true', 'false']
}

# Tuneamos los parametros y ajustamos el modelo
resultados_lgbm = Tuner(forecaster_fun= 'LightGBM', datos=datos, parametros=params, alpha= alpha, long_pred = long_pred)

# Graficamos el pronostico
plot_forecast(data = datos, forecast = resultados_lgbm['pred'], color = 'green', label = 'LightGBM')

# Guardamos las metricas
metricas.loc[len(metricas)] = ['LightGBM', resultados_lgbm['mape'], resultados_lgbm['score'], resultados_lgbm['tiempo']]
```

## Deep learning

```{python}
# LSTM (https://nixtlaverse.nixtla.io/neuralforecast/models.lstm.html)

# Definimos los parametros a tunear
parametros = {
    'max_steps' : [50, 100, 200, 500],
    'random_seed' : [seed],
    'encoder_n_layers' : [1,2,3],
    'decoder_layers' : [1,2,3]
    }

# Tuneamos los parametros y ajustamos el modelo
resultados_lstm = Tuner(forecaster_fun= 'LSTM', datos=datos, parametros= parametros, alpha= alpha, long_pred = long_pred)

# Graficamos el pronostico
plot_forecast(data = datos, forecast = resultados_lstm['pred'], color = 'violet', label = 'LSTM')

# Guardamos las metricas
metricas.loc[len(metricas)] = ['LSTM', resultados_lstm['mape'], resultados_lstm['score'], resultados_lstm['tiempo']]
```

```{python}
# TIME GPT (https://docs.nixtla.io/docs/capabilities-forecast-forecast)

# Definimos los parametros a tunear
parametros = {
    'finetune_loss' : ['mape'],
    'finetune_steps' : [1,2,5,10,15],
    'finetune_depth' : [1, 2, 3, 5]
    }

# Tuneamos los parametros y ajustamos el modelo
resultados_gpt = Tuner(forecaster_fun= 'TimeGPT', datos=datos, parametros= parametros, alpha= alpha, long_pred = long_pred)

# Graficamos el pronostico
plot_forecast(data = datos, forecast = resultados_gpt['pred'], color = 'violet', label = 'TimeGPT')

# Guardamos las metricas
metricas.loc[len(metricas)] = ['TimeGPT', resultados_gpt['mape'], resultados_gpt['score'], resultados_gpt['tiempo']]

```


```{python}
# Guardamos el ambiente
save_env(env_dict=globals(), filename="Ambiente/resultados.pkl")
```

