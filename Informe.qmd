---
title: "Tesis"
format: pdf
echo: False
warning: False
---


```{python}
# CARGA DE LIBRERIAS ------------------

# Para el manejo de estructuras de datos
import pandas as pd
import numpy as np

# Para dar formato fecha
from datetime import datetime

# Para graficos
import matplotlib.pyplot as plt
import seaborn as sea

# Para la transformacion de box y cox
from scipy import stats

# Para el calculo de autocorrelaciones
from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.graphics.tsaplots import plot_pacf
from statsmodels.tsa.stattools import acf, pacf

# Para ajustar modelos arima
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.arima.model import ARIMAResults
from pmdarima import auto_arima

# Para calcular el test de ljung box
import statsmodels.api as sm

# Para el test de kolmogorov-smirnov
import scipy.stats as stats

# Para calcular el error medio cuadratico
from sklearn.metrics import mean_squared_error


# Para time GPT
from nixtla import NixtlaClient
nixtla_client = NixtlaClient(api_key="nixak-ZIV9C5mIZ2HlEAMJG54njJV5YKC1unQTJNCLea1B52KuMaCaoLf4421VIBWSnauQRzh4JxA7aBmQbOuJ")
```

<!-- # Alquileres en Rosario -->

<!-- (fuente: zonaprop) -->

```{python}
#| eval: false

# CARGA DE DATOS ----------------

# Alquileres promedio en miles en todo rosario, + variacion mensual
alquileres = pd.read_csv("Datos/Index_Alquiler_prom_Rosario.csv")

# TRANSFORMACION DE DATOS ---------------

# Nobres de columnas
alquileres = alquileres.rename(columns={'ALQUILER $/MES' : 'alquiler', 'VARIACIÓN MENSUAL (%)': 'variacion'})

# Los ultimos meses estan en un formato diferente, por eso quito en todos el punto
alquileres['fecha'] = alquileres['fecha'].str.replace('.', '', regex=False)

```

```{python}
# Creo un diccionario para pasar los meses a numero 
meses = {
    'ene': '01', 'feb': '02', 'mar': '03', 'abr': '04', 
    'may': '05', 'jun': '06', 'jul': '07', 'ago': '08', 
    'sep': '09', 'oct': '10', 'nov': '11', 'dic': '12'
}
```

```{python}
#| eval: false

# Cambio la abreviacion del mes por su numero
alquileres['fecha'] = alquileres['fecha'].apply(
    lambda x: x.replace(x.split(' ')[0], meses.get(x.split(' ')[0].lower(), '')) if isinstance(x, str) else x
)

# Convierto a formato fecha
alquileres['fecha'] = pd.to_datetime(alquileres['fecha'], format='%m %y')

# Muestro los datos
print(alquileres.head(3),alquileres.tail(3))

```


```{python}
#| eval: false

plt.plot(alquileres['fecha'], alquileres['alquiler'], marker = '.')
plt.title('Precio de alquileres promedio en Rosario (en miles)')
plt.xlabel('Año')
plt.ylabel('Precio')
plt.show()

```

<!-- No tiene estacionalidad y solo aumenta -->

```{python}
#| eval: false

plt.plot(alquileres['fecha'], alquileres['variacion'], marker = '.')
plt.title('Variacion mensual en el precio de alquileres promedio en Rosario')
plt.xlabel('Año')
plt.ylabel('Variacion (%)')
plt.show()

```

<!-- Y la variacion mensual parece tener un comportamiento muy raro con muchos outlayers y sin una estacionalidad clara -->


# Empleados promedio mensuales en Argentina, rubro: Enseñanza
(Personas con empleo asalariado registrado en el sector privado, según rama de actividad de la ocupación principal. Con estacionalidad. Total país. En miles. INDEC)

```{python}
empleo = pd.DataFrame({
    'fecha': ["ene-09", "feb-09", "mar-09", "abr-09", "may-09", "jun-09", "jul-09", "ago-09", "sep-09", "oct-09", "nov-09", "dic-09", "ene-10", "feb-10", "mar-10", "abr-10", "may-10", "jun-10", "jul-10", "ago-10", "sep-10", "oct-10", "nov-10", "dic-10", "ene-11", "feb-11", "mar-11", "abr-11", "may-11", "jun-11", "jul-11", "ago-11", "sep-11", "oct-11", "nov-11", "dic-11", "ene-12", "feb-12", "mar-12", "abr-12", "may-12", "jun-12", "jul-12", "ago-12", "sep-12", "oct-12", "nov-12", "dic-12", "ene-13", "feb-13", "mar-13", "abr-13", "may-13", "jun-13", "jul-13", "ago-13", "sep-13", "oct-13", "nov-13", "dic-13", "ene-14", "feb-14", "mar-14", "abr-14", "may-14", "jun-14", "jul-14", "ago-14", "sep-14", "oct-14", "nov-14", "dic-14", "ene-15", "feb-15", "mar-15", "abr-15", "may-15", "jun-15", "jul-15", "ago-15", "sep-15", "oct-15", "nov-15", "dic-15", "ene-16", "feb-16", "mar-16", "abr-16", "may-16", "jun-16", "jul-16", "ago-16", "sep-16", "oct-16", "nov-16", "dic-16", "ene-17", "feb-17", "mar-17", "abr-17", "may-17", "Jun-17", "Jul-17", "ago-17", "sep-17", "oct-17", "nov-17", "dic-17", "ene-18", "feb-18", "mar-18", "abr-18", "may-18", "jun-18", "jul-18", "ago-18", "sep-18", "oct-18", "nov-18", "dic-18", "ene-19", "feb-19", "mar-19", "abr-19", "may-19", "jun-19", "jul-19", "ago-19", "sep-19", "oct-19", "nov-19", "dic-19", "ene-20", "feb-20", "mar-20", "abr-20", "may-20", "jun-20", "jul-20", "ago-20", "sep-20", "oct-20", "nov-20", "dic-20", "ene-21", "feb-21", "mar-21", "abr-21", "may-21", "jun-21", "jul-21", "ago-21", "sep-21", "oct-21", "nov-21", "dic-21", "ene-22", "feb-22", "mar-22", "abr-22", "may-22", "jun-22", "jul-22", "ago-22", "sep-22", "oct-22", "nov-22", "dic-22", "ene-23", "feb-23", "mar-23", "abr-23", "may-23", "jun-23", "jul-23", "ago-23", "sep-23", "oct-23", "nov-23", "dic-23", "ene-24", "feb-24", "mar-24", "abr-24", "may-24", "jun-24", "jul-24", "ago-24"
],
    'empleados': [309.7, 309.7, 316.6, 322.7, 325.4, 332.1, 325.7, 328.8, 330.9, 331.7, 331.4, 330.0, 315.7, 316.4, 324.6, 331.6, 335.2, 341.7, 337.6, 339.1, 340.6, 341.8, 340.5, 339.7, 326.1, 329.3, 337.4, 344.5, 348.4, 355.0, 350.7, 353.9, 355.2, 355.9, 356.0, 354.7, 339.1, 342.1, 351.5, 356.0, 358.7, 365.0, 360.8, 362.1, 362.4, 364.3, 364.7, 364.0, 345.1, 352.1, 359.4, 367.5, 368.2, 373.8, 368.4, 370.9, 371.9, 372.4, 372.1, 370.5, 351.3, 357.2, 366.9, 373.5, 377.6, 381.6, 378.5, 380.7, 384.1, 385.2, 383.9, 381.1, 366.0, 368.3, 381.4, 390.1, 392.5, 395.8, 392.4, 395.3, 396.1, 396.5, 395.4, 391.3, 375.2, 381.4, 394.3, 398.5, 401.4, 403.7, 399.8, 402.5, 403.0, 402.9, 402.3, 398.1, 381.7, 384.1, 400.2, 403.5, 407.3, 410.2, 408.0, 409.9, 410.4, 410.9, 410.2, 405.7, 389.6, 392.8, 407.2, 411.6, 414.3, 416.2, 413.8, 419.0, 418.8, 419.6, 417.6, 412.3, 396.9, 398.8, 412.3, 417.0, 418.7, 419.5, 417.4, 419.4, 420.2, 420.3, 418.3, 412.7, 397.6, 398.9, 411.0, 407.6, 406.0, 405.1, 403.3, 402.4, 400.5, 399.3, 398.2, 396.6, 388.3, 389.8, 403.1, 406.3, 405.9, 405.6, 404.4, 409.2, 410.7, 411.2, 411.0, 407.4, 392.4, 395.9, 413.1, 417.3, 419.6, 421.5, 418.6, 421.9, 422.3, 422.5, 421.4, 416.5, 400.2, 402.5, 419.8, 423.4, 426.3, 427.9, 425.7, 429.0, 428.7, 428.0, 426.9, 421.4, 404.6, 406.3, 420.0, 423.8, 425.6, 426.2, 424.4, 427.0
]
})

# Cambio la abreviacion del mes por su numero
empleo['fecha'] = empleo['fecha'].apply(
    lambda x: x.replace(x.split('-')[0], meses.get(x.split('-')[0].lower(), '')) if isinstance(x, str) else x
)


# Convierto a formato fecha
empleo['fecha'] = pd.to_datetime(empleo['fecha'], format='%m-%y')

# Muestro los datos
print(empleo.head(3),empleo.tail(3))

# Grafico los datos
plt.plot(empleo['fecha'], empleo['empleados'], marker = '.')
plt.title('Empleados promedio en Rosario en la industria de enseñanza en el sector privado (en miles)')
plt.xlabel('Año')
plt.ylabel('Empleados promedio')
plt.show()

```

Tiene estacionalidad y tendencia

Hay para muchos mas rubros

Solo tengo datos hasta agosto

Inicialmente habia tomado datos solo hasta febrero para pronosticar 6 meses, pero al tener solo 2 observaciones en 2024 afectaba mucho la variancia de este año. Además, la serie es muy larga, asi que voy a trabajar con 6 años nomás (2018-2023)

```{python}

# Separo en datos de entrenamiento y de testeo
empleo_test = empleo[180:]
empleo = empleo[108:180]
```

```{python}
sea.boxplot(x = empleo["fecha"].dt.year, y = empleo["empleados"])
```

No parece haber necesidad de transformar la variable


```{python}
fitted_data, fitted_lambda = stats.boxcox(empleo["empleados"])

empleo['emp_transformada'] = fitted_data
```

```{python}
sea.lineplot(x = empleo["fecha"], y = empleo['emp_transformada'])
plt.title('Serie transformada con box y cox')
plt.text(pd.to_datetime('2020-03-01'), empleo['emp_transformada'].max() * 0.2, 
         f'Párametro de\n Box y Cox: {fitted_lambda.round(2)}', fontsize=12, color='black')

```

Finalmnente decido no usar la transformacion

Diferencio estacionalmente la serie:

```{python}
empleo["emp_estacional"] = empleo['empleados'].diff(12)

sea.lineplot(x = empleo["fecha"], y = empleo['emp_estacional'])
```

diferencio la serie en la parte estacionaria

```{python}
empleo["emp_estacionario"] = empleo['emp_estacional'].diff(1)

sea.lineplot(x = empleo["fecha"], y = empleo['emp_estacionario'])
```

Parece ser estacionaria pero con grandes outlayers

```{python}
empleo_diff = pd.DataFrame({
    'fecha' : empleo['fecha'],
    'empleados' : empleo['emp_estacionario']
})

empleo_diff = empleo_diff.iloc[13:]
```

```{python}
# Funcion para crear los graficos de autocorrelacion

def autocorr_plot(vector, lags, atype = 'acf'):

    if atype == 'acf':
        autocorr = acf(vector, nlags=lags)
        lags = np.arange(lags+1)
    else:
        autocorr = pacf(vector, nlags=lags, method = 'ywm')
        lags = np.arange(lags+1)

        autocorr = autocorr[1:]
        lags = lags[1:]

    # Calculo las autocorrelaciones
    autocorrelaciones = pd.DataFrame({
        'lag' : lags,
        atype : autocorr
    })

    # Defino las bandas limite
    upper_bound = 1.96/np.sqrt(len(vector))
    lower_bound = -1.96/np.sqrt(len(vector))

    # Cambio el color del punto si supera el limite
    col = np.where(
        autocorrelaciones[atype] < lower_bound,'b',
        np.where(autocorrelaciones[atype] > upper_bound, 'b', 'green'))

    # Creo los bastones
    plt.vlines(x=autocorrelaciones['lag'], ymin=0, ymax= autocorrelaciones[atype], color='black', alpha=0.4)

    # Creo los puntos y les asigno color segun pasen o no la banda
    plt.scatter(x = autocorrelaciones['lag'], y = autocorrelaciones[atype], color=col, alpha=1, marker = '.')

    # Grafico los limites de la banda
    plt.axhline(y = 0, color = 'black')
    plt.axhline(y = upper_bound, color = 'green', ls = '--')
    plt.axhline(y = lower_bound, color = 'green', ls = '--')
    plt.axhspan(upper_bound, lower_bound, color='green', alpha=0.15)
    plt.axhspan(1, 2, color='grey', alpha=0.5)
    plt.axhspan(-1, -2, color='grey', alpha=0.5)
    plt.ylim(-1.15,1.15)

```


```{python}
# Grafico las funciones de autocorrelacion

plt.subplot(2,1,1)
autocorr_plot(empleo_diff['empleados'], lags=25)
plt.subplot(2,1,2)
autocorr_plot(empleo_diff['empleados'], lags=25, atype='pacf')

```

La serie parece tener una componente MA tanto en la parte estacional como en la estacionaria

# Seleccion manual

```{python}
# Ajusto un modelo con lo visto en los graficos de autocorrelacion
model_ma = ARIMA(
    empleo['empleados'], 
    order=(0, 1, 1), 
    seasonal_order=(0,1,1,12))

model_ma_fit = model_ma.fit()

model_ma_fit.summary()
```


## Seleccion automatica
```{python}
# Busco un modelo con seleccion paso a paso
stepwise_fit = auto_arima(empleo['empleados'], 
                        start_p = 0, max_p = 3,
                        start_q = 0, max_q = 3,
                        start_P = 0, max_P = 3,
                        start_Q = 0, max_Q = 3,
                        m = 12,
                        trace = False, 
                        error_action ='ignore',   # we don't want to know if an order does not work 
                        suppress_warnings = True,  # we don't want convergence warnings 
                        stepwise = True)

```


```{python}
# Veo las caracteristicas de los modelos ajustados
stepwise_fit.summary()
```

```{python}
phi = [1, 0.9769, 0.8867, 0.8524]  # Sustituye phi1, phi2, phi3 con tus valores

# Calcula las raíces
roots = np.roots(phi)

# Verifica el módulo de las raíces
admisible = all(abs(root) > 1 for root in roots)
```

Modelos seleccionados:

- $SARIMA(0,1,1)(0,1,1)_{12}$

Con $q = 0.3888$ y $Q = -0.9983$ | $AIC = 253.003$

Es admisible

- $SARIMA(1,1,0)(3,1,1)_{12}$

Con $p = 0.268$, $P_1 = -0.9769$, $P_2 = -0.8867$, $P_3 = -0.8524$, $Q = -0.4374$ | $AIC = 248.636$

No es admisible

Probamos el modelo $SARIMA(1,1,0)(2,1,1)_{12}$

```{python}
# Trato de que el modelo con seleccion manual sea admisible
model_auto2 = ARIMA(
    empleo['empleados'], 
    order=(1, 1, 0), 
    seasonal_order=(2,1,1,12))

model_auto2_fit = model_auto2.fit()

model_auto2_fit.summary()
```

- $SARIMA(1,1,0)(2,1,1)_{12}$

Con $p = 0.4025$, $P_1 = -0.1533$, $P_2 = -0.3886$, $Q = -0.997$ | $AIC = 250$

Es admisible

Tambien voy a probar el mismo modelo anterior, pero con la componente ma en lugar de ar en la parte estacionaria, ya que es lo que se ve en los graficos de autocorrelacion

```{python}
# Trato de que el modelo con seleccion manual sea admisible
model_auto3 = ARIMA(
    empleo['empleados'], 
    order=(0, 1, 1), 
    seasonal_order=(2,1,1,12))

model_auto3_fit = model_auto3.fit()

model_auto3_fit.summary()
```

- $SARIMA(0,1,1)(2,1,1)_{12}$

Con $q = 0.3989$, $P_1 = -0.1333$, $P_2 = -0.4221$, $Q = -0.997$ | $AIC = 250.4$

Es admisible

## Comprobacion de supuestos

Hago la comprobacion de supuestos unicamente con los modelos admisibles

```{python}
# Calculo los residuos
# resid_auto = stepwise_fit.resid()

resid_ma = model_ma_fit.resid

resid_auto2 = model_auto2_fit.resid

resid_auto3 = model_auto3_fit.resid
```


```{python}
# Los estandarizo

resid_auto2_est = (resid_auto2 - np.mean(resid_auto2))/ np.std(resid_auto2)

resid_auto3_est = (resid_auto3 - np.mean(resid_auto3))/ np.std(resid_auto3)

resid_ma_est = (resid_ma - np.mean(resid_ma))/ np.std(resid_ma)
```

### $SARIMA(0,1,1)(0,1,1)_{12}$

```{python}
#| fig-width: 8
#| fig-height: 6

# Histograma
plt.subplot(2,2,1)
sea.histplot(resid_ma_est, bins=100)

# Test de normalidad
ks = stats.kstest(resid_ma_est,'norm').pvalue
if ks < 0.0001:
    ks = '< 0.0001'
else:
    ks = round(ks, 4)

# resid_ma_est_sin_out = resid_ma_est[(resid_ma_est > -3) & (resid_ma_est < 3)]

plt.text(1, 20, 
         f'P-value test de\nnormalidad K-S: {ks}', fontsize=6, color='black')

# Serie de los residuos
plt.subplot(2,2,2)
sea.lineplot(x = empleo['empleados'], y = resid_ma_est)
plt.axhline(y = 3, color = 'black', ls = '--')
plt.axhline(y = -3, color = 'black', ls = '--')
plt.ylabel('')

# Autocorrelaciones
plt.subplot(2,2,3)
autocorr_plot(resid_ma_est, lags=30)
plt.title('')

# Test de Ljung-box
p_value = sm.stats.acorr_ljungbox(resid_ma_est, lags= range(1,20) , return_df=True)['lb_pvalue'].min()

plt.text(10, -0.85, 
         f'Test de Ljung-Box\nMenor P-value: {round(p_value,4)}', fontsize=8, color='black')


plt.subplot(2,2,4)
autocorr_plot(resid_ma_est, lags=30, atype='pacf')
plt.title('')

```


### $SARIMA(1,1,0)(2,1,1)_{12}$

```{python}
#| fig-width: 8
#| fig-height: 6

# Histograma
plt.subplot(2,2,1)
sea.histplot(resid_auto2_est, bins=30)

# Test de normalidad
ks = stats.kstest(resid_auto2_est,'norm').pvalue
if ks < 0.0001:
    ks = '< 0.0001'
else:
    ks = round(ks, 4)

# resid_ma_est_sin_out = resid_ma_est[(resid_ma_est > -3) & (resid_ma_est < 3)]

plt.text(1, 20, 
         f'P-value test de\nnormalidad K-S: {ks}', fontsize=6, color='black')


# Serie de los residuos
plt.subplot(2,2,2)
sea.lineplot(x = empleo['empleados'], y = resid_auto2_est)
plt.axhline(y = 3, color = 'black', ls = '--')
plt.axhline(y = -3, color = 'black', ls = '--')
plt.ylabel('')

# Autocorrelaciones
plt.subplot(2,2,3)
autocorr_plot(resid_auto2_est, lags=30)
plt.title('')

# Test de Ljung-box
p_value = sm.stats.acorr_ljungbox(resid_auto2_est, lags= range(1,20) , return_df=True)['lb_pvalue'].min()

plt.text(10, -0.85, 
         f'Test de Ljung-Box\nMenor P-value: {round(p_value,4)}', fontsize=8, color='black')



plt.subplot(2,2,4)
autocorr_plot(resid_auto2_est, lags=30, atype='pacf')
plt.title('')
```


### $SARIMA(0,1,1)(2,1,1)_{12}$

```{python}
#| fig-width: 8
#| fig-height: 6

# Histograma
plt.subplot(2,2,1)
sea.histplot(resid_auto3_est, bins=30)

# Test de normalidad
ks = stats.kstest(resid_auto3_est,'norm').pvalue
if ks < 0.0001:
    ks = '< 0.0001'
else:
    ks = round(ks, 4)

# resid_ma_est_sin_out = resid_ma_est[(resid_ma_est > -3) & (resid_ma_est < 3)]

plt.text(1, 20, 
         f'P-value test de\nnormalidad K-S: {ks}', fontsize=6, color='black')


# Serie de los residuos
plt.subplot(2,2,2)
sea.lineplot(x = empleo['empleados'], y = resid_auto3_est)
plt.axhline(y = 3, color = 'black', ls = '--')
plt.axhline(y = -3, color = 'black', ls = '--')
plt.ylabel('')

# Autocorrelaciones
plt.subplot(2,2,3)
autocorr_plot(resid_auto3_est, lags=30)
plt.title('')

# Test de Ljung-box
p_value = sm.stats.acorr_ljungbox(resid_auto3_est, lags= range(1,20) , return_df=True)['lb_pvalue'].min()

plt.text(10, -0.85, 
         f'Test de Ljung-Box\nMenor P-value: {round(p_value,4)}', fontsize=8, color='black')


plt.subplot(2,2,4)
autocorr_plot(resid_auto3_est, lags=30, atype='pacf')
plt.title('')
```

Comentarios en general:

Para todos los modelos se rechaza la normalidad de los residuos incluso sacando los 2 outlayers. La independencia de los residuos tambien se cumple para todos los modelos.

# Pronosticos


```{python}
# Pronostico con el modelo automatico los ultimos 6 meses
# pronostico_auto = stepwise_fit.predict(n_periods = 7, alpha = 0.05)
pronostico_ma = model_ma_fit.get_forecast(steps=9)
pronostico_auto2 = model_auto2_fit.get_forecast(steps=9)
pronostico_auto3 = model_auto3_fit.get_forecast(steps=9)
```


```{python}
empleo_total = pd.concat([empleo[['fecha','empleados']], empleo_test])
pronosticos = empleo_test

# pronosticos['pr_auto'] = pronostico_auto
pronosticos['pr_ma'] = pronostico_ma.predicted_mean
pronosticos['pr_auto2'] = pronostico_auto2.predicted_mean
pronosticos['pr_auto3'] = pronostico_auto3.predicted_mean


# intervalos de confianza
pronosticos['ma_ic_90_inf'] = pronostico_ma.conf_int(90)['lower empleados']
pronosticos['ma_ic_90_sup'] = pronostico_ma.conf_int(90)['upper empleados']

pronosticos['auto2_ic_90_inf'] = pronostico_auto2.conf_int(90)['lower empleados']
pronosticos['auto2_ic_90_sup'] = pronostico_auto2.conf_int(90)['upper empleados']

pronosticos['auto3_ic_90_inf'] = pronostico_auto3.conf_int(90)['lower empleados']
pronosticos['auto3_ic_90_sup'] = pronostico_auto3.conf_int(90)['upper empleados']
```

```{python}
#| echo: true

# Pronostico Time gpt
pro_timeGPT = nixtla_client.forecast(
    df = empleo, h = 8,time_col= "fecha", 
    target_col= "empleados",
    level=[90], finetune_steps=40, finetune_loss= "mape")
```

```{python}
print(pro_timeGPT.head(3),pro_timeGPT.tail(3))
```

Leyenda:

- $SARIMA(0,1,1)(0,1,1)_{12}$: Rojo

- $SARIMA(1,1,0)(2,1,1)_{12}$: Azul

- $SARIMA(0,1,1)(2,1,1)_{12}$: Violeta

- TimeGPT: Verde

```{python}
#| fig-width: 8
#| fig-height: 6


# Pronostico ma
plt.subplot(2,2,1)
sea.lineplot(x = empleo_total['fecha'],y = empleo_total['empleados'], color = 'black')
sea.lineplot(x = pronosticos['fecha'], y = pronosticos['pr_ma'], color = 'r')

plt.fill_between(pronosticos['fecha'], pronosticos['ma_ic_90_inf'], pronosticos['ma_ic_90_sup'], color = 'r', alpha = 0.3, label = 'IC 90%')

plt.xlim(pd.to_datetime('2023-12-01'),pd.to_datetime('2024-09-01'))
plt.ylim(400,440)
plt.gcf().autofmt_xdate()

# Pronostico auto2
plt.subplot(2,2,2)
sea.lineplot(x = empleo_total['fecha'],y = empleo_total['empleados'], color = 'black')
sea.lineplot(x = pronosticos['fecha'], y = pronosticos['pr_auto2'], color = 'b')

plt.fill_between(pronosticos['fecha'], pronosticos['auto2_ic_90_inf'], pronosticos['auto2_ic_90_sup'], color = 'b', alpha = 0.3, label = 'IC 90%')

plt.xlim(pd.to_datetime('2023-12-01'),pd.to_datetime('2024-09-01'))
plt.ylim(400,440)
plt.gcf().autofmt_xdate()

# Pronostico auto3
plt.subplot(2,2,3)
sea.lineplot(x = empleo_total['fecha'],y = empleo_total['empleados'], color = 'black')
sea.lineplot(x = pronosticos['fecha'], y = pronosticos['pr_auto3'], color = 'blueviolet')

plt.fill_between(pronosticos['fecha'], pronosticos['auto3_ic_90_inf'], pronosticos['auto3_ic_90_sup'], color = 'blueviolet', alpha = 0.3, label = 'IC 90%')

plt.xlim(pd.to_datetime('2023-12-01'),pd.to_datetime('2024-09-01'))
plt.ylim(400,440)
plt.gcf().autofmt_xdate()

# Pronostico Time GPT
plt.subplot(2,2,4)
sea.lineplot(x = empleo_total['fecha'],y = empleo_total['empleados'], color = 'black')
sea.lineplot(x = pro_timeGPT['fecha'], y = pro_timeGPT['TimeGPT'], color = 'green')

plt.fill_between(pronosticos['fecha'], pro_timeGPT['TimeGPT-lo-90'], pro_timeGPT['TimeGPT-hi-90'], color = 'green', alpha = 0.3, label = 'IC 90%')

plt.xlim(pd.to_datetime('2023-12-01'),pd.to_datetime('2024-09-01'))
plt.ylim(400,440)
plt.gcf().autofmt_xdate()
```

El area marcada denota el intervalo de confianza del 90%

```{python}
# Calculo del MAPE
# Uno todos los pronosticos en un dataframe
pronosticos_mape = pronosticos[['fecha', 'empleados', 'pr_ma', 'pr_auto2', 'pr_auto3']].copy()

pronosticos_mape = pronosticos_mape.set_index('fecha')

time_gpt = pro_timeGPT.set_index('fecha')

pronosticos_mape = pd.concat([pronosticos_mape, time_gpt[['TimeGPT']]], axis=1)

# Defino una funcion para calcular el mape, calculando la media del valor absoluto de la resta entre el valor real y el pronosticado, dividiendo por el valor real y multiplicando por 100

def calculate_mape(actual, forecast):
    return np.mean(np.abs((actual - forecast) / actual)) * 100

pd.DataFrame({
    'Modelo': ['$SARIMA(0,1,1)(0,1,1)_{12}$', '$SARIMA(1,1,0)(2,1,1)_{12}$', '$SARIMA(0,1,1)(2,1,1)_{12}$', 'Time GPT'],
    'MAPE': [calculate_mape(pronosticos_mape['empleados'], pronosticos_mape['pr_ma']),
    calculate_mape(pronosticos_mape['empleados'], pronosticos_mape['pr_auto2']),
    calculate_mape(pronosticos_mape['empleados'], pronosticos_mape['pr_auto3']),
    calculate_mape(pronosticos_mape['empleados'], pronosticos_mape['TimeGPT'])
    ]
})

```

Dado que los pronosticos con time gpt fueron muy malos voy a tratar con distintos parametros. Muy seguramente falla mucho por el sobreajuste, ya quue se hicieron 40 pasos de tuneo de parametros.

### Distintos pronosticos con time gpt

```{python}
#| echo: true

# Pruebo las opciones por defecto
time_gpt1 = nixtla_client.forecast(
    df = empleo, h = 8,time_col= "fecha", 
    target_col= "empleados",
    freq = 'M',
    level=[90])


# Pruebo usar 5 pasos de ajuste
time_gpt2 = nixtla_client.forecast(
    df = empleo, h = 8,time_col= "fecha", 
    target_col= "empleados",
    level=[90], finetune_steps=5)


# Pruebo usar la funcion de perdida mape
time_gpt3 = nixtla_client.forecast(
    df = empleo, h = 8,time_col= "fecha", 
    target_col= "empleados",
    level=[90], finetune_loss= "mape")

# Pruebo usar la funcion de perdida mape con 5 pasos de ajuste
time_gpt4 = nixtla_client.forecast(
    df = empleo, h = 8,time_col= "fecha", 
    target_col= "empleados",
    level=[90], finetune_loss= "mape", finetune_steps=10)
    
```


```{python}
#| fig-width: 8
#| fig-height: 6


# Pronosito opciones 1
plt.subplot(2,2,1)
sea.lineplot(x = empleo_total['fecha'],y = empleo_total['empleados'], color = 'black')
sea.lineplot(x = time_gpt1['fecha'], y = time_gpt1['TimeGPT'], color = 'green')

plt.fill_between(pronosticos['fecha'], time_gpt1['TimeGPT-lo-90'], time_gpt1['TimeGPT-hi-90'], color = 'green', alpha = 0.3, label = 'IC 90%')

plt.xlim(pd.to_datetime('2023-12-01'),pd.to_datetime('2024-09-01'))
plt.ylim(400,440)
plt.gcf().autofmt_xdate()

# Pronosito opciones 2
plt.subplot(2,2,2)
sea.lineplot(x = empleo_total['fecha'],y = empleo_total['empleados'], color = 'black')
sea.lineplot(x = time_gpt2['fecha'], y = time_gpt2['TimeGPT'], color = 'r')

plt.fill_between(pronosticos['fecha'], time_gpt2['TimeGPT-lo-90'], time_gpt2['TimeGPT-hi-90'], color = 'r', alpha = 0.3, label = 'IC 90%')

plt.xlim(pd.to_datetime('2023-12-01'),pd.to_datetime('2024-09-01'))
plt.ylim(400,440)
plt.gcf().autofmt_xdate()


# Pronosito opciones 3
plt.subplot(2,2,3)
sea.lineplot(x = empleo_total['fecha'],y = empleo_total['empleados'], color = 'black')
sea.lineplot(x = time_gpt3['fecha'], y = time_gpt3['TimeGPT'], color = 'b')

plt.fill_between(pronosticos['fecha'], time_gpt3['TimeGPT-lo-90'], time_gpt3['TimeGPT-hi-90'], color = 'b', alpha = 0.3, label = 'IC 90%')

plt.xlim(pd.to_datetime('2023-12-01'),pd.to_datetime('2024-09-01'))
plt.ylim(400,440)
plt.gcf().autofmt_xdate()


# Pronosito opciones 4
plt.subplot(2,2,4)
sea.lineplot(x = empleo_total['fecha'],y = empleo_total['empleados'], color = 'black')
sea.lineplot(x = time_gpt4['fecha'], y = time_gpt4['TimeGPT'], color = 'blueviolet')

plt.fill_between(pronosticos['fecha'], time_gpt4['TimeGPT-lo-90'], time_gpt4['TimeGPT-hi-90'], color = 'blueviolet', alpha = 0.3)

plt.xlim(pd.to_datetime('2023-12-01'),pd.to_datetime('2024-09-01'))
plt.ylim(400,440)
plt.gcf().autofmt_xdate()
```

```{python}
time_gpt1 = time_gpt1.set_index('fecha')
time_gpt2 = time_gpt2.set_index('fecha')
time_gpt3 = time_gpt3.set_index('fecha')
time_gpt4 = time_gpt4.set_index('fecha')

pd.DataFrame({
    'Modelo': ['Time GPT conf 1', 'Time GPT conf 2', 'Time GPT conf 3', 'Time GPT conf 4'],
    'MAPE': [calculate_mape(pronosticos_mape['empleados'], time_gpt1['TimeGPT']),
    calculate_mape(pronosticos_mape['empleados'], time_gpt2['TimeGPT']),
    calculate_mape(pronosticos_mape['empleados'], time_gpt3['TimeGPT']),
    calculate_mape(pronosticos_mape['empleados'], time_gpt4['TimeGPT'])
    ]
})
```

Los pronosticos mejoraron considerablemente pero siguen siendo peores que los metodos clasicos por ahora, hay que seguir viendo que problemas pueden tener y como solucionarlo.