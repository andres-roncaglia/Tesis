---
title: "Tesis"
format: pdf
echo: False
warning: False
---


```{python}
# CARGA DE LIBRERIAS ------------------

# Para el manejo de estructuras de datos
import pandas as pd
import numpy as np

# Para dar formato fecha
from datetime import datetime

# Para graficos
import matplotlib.pyplot as plt
import seaborn as sns

# Para la transformacion de box y cox
from scipy import stats

# Para el calculo de autocorrelaciones
from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.graphics.tsaplots import plot_pacf
from statsmodels.tsa.stattools import acf, pacf

# Para ajustar modelos arima
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.arima.model import ARIMAResults
from pmdarima import auto_arima

# Para calcular el test de ljung box
import statsmodels.api as sm

# Para el test de kolmogorov-smirnov
import scipy.stats as stats

# Para calcular el error medio cuadratico
from sklearn.metrics import mean_squared_error

# Para cargar las claves
import creds

# Para time GPT
from nixtla import NixtlaClient
nixtla_client = NixtlaClient(api_key= creds.api_key)

# Para realizar consultas a la base de datos
import urllib.parse
import requests

# Para guardar y cargar los modelos
from joblib import dump, load

# Para estandarizar los datos
from sklearn.preprocessing import MinMaxScaler

# Para medir el tiempo que tarda en ajustar los modelos
import time
```



```{python}
# Creamos una función para realizar llamadas a la API de datos argentina
def get_api_call(ids, **kwargs):
    API_BASE_URL = "https://apis.datos.gob.ar/series/api/"
    kwargs["ids"] = ",".join(ids)
    return "{}{}?{}".format(API_BASE_URL, "series", urllib.parse.urlencode(kwargs))
```


```{python}
# Llamada a la API y carga de datos

api_call = get_api_call(["364.3_LITORAL_GAGAS__11"], start_date="2016-01")

json = requests.get(api_call).json()

datos = pd.DataFrame(json['data'], columns = ['fecha', 'consumo'])

datos['fecha'] = pd.to_datetime(datos['fecha'], format='%Y-%m-%d')
```


```{python}
datos = pd.read_csv(filepath_or_buffer= 'Datos/exportaciones-actividad-saldocomercial-rangos-exportacion-empresa-exportadora-mensual.csv')

datos = datos[['indice_tiempo','litoral_gas']]

datos.columns = ['fecha', 'consumo']

datos['fecha'] = pd.to_datetime(datos['fecha'], format='%Y-%m-%d')

datos.dropna(inplace=True)
```

```{python}
# Tabla con los primeros y ultimos datos
print(datos.head(3),datos.tail(3))

# Grafico los datos
plt.plot(datos['fecha'], datos['consumo'], marker = '.')
plt.title('Consumo de gas natural')
plt.xlabel('Año')
plt.ylabel('Consumo (millones de metros cúbicos)')
plt.show()

```


```{python}
# Divido el conjunto de datos en entrenamiento y testeo

corte = len(datos)-12

datos.columns = ['ds', 'y']

# Normalizamos 'y' para que los modelos deep learning puedan converger mejor
# scaler = MinMaxScaler(feature_range=(-1, 1)) 
# datos[['y']] = scaler.fit_transform(datos[['y']])

datos_train = datos[:corte]
datos_test = datos[corte:]

print(datos_test.head())

```


```{python}
#| fig-cap: 'Distribución del consumo de gas natural de Litoral Gas por año'
#| label: fig-dist-box
#| eval: False

sns.boxplot(x = datos_train["fecha"].dt.year, y = datos_train["consumo"])

fitted_data, fitted_lambda, fitted_lambda_ic = stats.boxcox(datos_train["consumo"], alpha = 0.05)

print(fitted_lambda_ic)
```

Observando la @fig-dist-box parecería ser que la variabilidad del consumo de gas natural no es la misma durante los años, sin embargo, el intervalo de confianza para el parámetro de transformación de Box y Cox resulta ser `python round(fitted_lambda_ic,3)` con un nivel de significación del 5%. Esto indica que la hipótesis nula que sostiene que la variancia del consumo es la misma año a año, y por lo tanto no hay necesidad de hacer transformar la variable.

# Predicciones con machine learning


```{python}
# Prueba con sktime

from sktime.forecasting.base import ForecastingHorizon

from sktime.forecasting.fbprophet import Prophet

from sktime.forecasting.arima import AutoARIMA

from sktime.forecasting.chronos import ChronosForecaster

from sktime.forecasting.neuralforecast import NeuralForecastLSTM

from sktime.performance_metrics.forecasting import mean_absolute_percentage_error

from sktime.split import temporal_train_test_split

```

```{python}
metricas = pd.DataFrame(columns=(['Modelo', 'MAPE', 'Interval Score', 'Tiempo']))
```


```{python}
# Interval Score

def interval_score(obs, lower, upper, alpha):

    upper = upper.values
    lower = lower.values
    obs = obs.values

    # Ancho del intervalo
    W = upper - lower

    # Penalización por sobre-estimación
    cuantil_sobreestimado = lower > obs
    diferencia_inferior = lower - obs
    O = 2/alpha * (cuantil_sobreestimado * diferencia_inferior)

    # Penalización por sub-estimación
    cuantil_subestimado = upper < obs
    diferencia_superior = obs - upper
    U = 2/alpha * (cuantil_subestimado * diferencia_superior)

    # Interval Score
    score = np.average(W + O + U)

    return score



```

```{python}
# Tuner de hiperparametros

def tuner(forecaster_fun, datos_train, datos_test, parametros = '', metrica = 'MAPE'):

    # Dado que estamos ajustando parametros, no podemos usar el conjunto de entrenamiento en su totalidad, debemos particionarlo para evitar el sobreajuste
    train_y, test_y = temporal_train_test_split(datos_train['y'], test_size=0.1)

    num_pred = ForecastingHorizon(test_y.index, is_relative=False)

    # Si no se definen parametros, simplemente se devuelve el modelo base ajustado
    if not isinstance(parametros, dict):
        
        fh = ForecastingHorizon(datos_test.index, is_relative=False)

        timer_comienzo = time.time() # Empiezo a medir cuanto tarda en ajustar
        forecaster = forecaster_fun().fit(datos_train['y'])
          
        # Obtenemos predicciones
        pred = forecaster.predict(fh)
        pred_int = forecaster.predict_interval(fh, coverage=0.9)
        timer_final = time.time()
        tiempo = timer_final - timer_comienzo

        # Calculamos MAPE
        mape_final = mean_absolute_percentage_error(datos_test['y'], pred)

        # Calculamos Interval Score
        pred_int.columns = ['lower', 'upper']
        score_final = interval_score(obs=datos_test['y'], lower=pred_int['lower'], upper=pred_int['upper'], alpha = 0.05)

        # Graficamos el pronostico
        datos = pd.concat([datos_train, datos_test])
        plt.plot(datos['ds'], datos['y'])
        sns.lineplot(x = datos['ds'], y= pred, color = 'red', label = 'Prediccion')
        plt.fill_between(datos_test['ds'], pred_int['lower'], pred_int['upper'], color = 'red', alpha = 0.3, label = 'IC: 0.9')

        # Devolvemos las predicciones
        return pred, mape_final, score_final, tiempo, []


    
    mapes = []
    scores = []
    nombre_cols = list(parametros.keys())

    # Expandimos la grilla de parametros para evaluar todas las opciones
    ## Paso 1: Pasar los valores del diccionario como vectores de una lista
    grilla_lista = list(parametros.values())

    ## Paso 2: Expandimos la lista por todos los parametros. '*' sirve para desempaquetar los elementos de la lista, en lugar de pasarse como '[elem1, elem2]' se pasan como 'elem1, elem2'
    grilla_expan = list(map(np.ravel, np.meshgrid(*grilla_lista)))

    ## Paso 3: Guardamos todo como un Dataframe
    grilla = pd.DataFrame(np.array(grilla_expan).T, columns= nombre_cols)

    # Vamos a probar cada combinacion de filas 
    for j in range(0,grilla.shape[0]):

        # Primero pasamos la fila como diccionario para usar los argumentos
        kwargs = grilla.iloc[j].to_dict()
            

        # TimeGPT no necesita una funcion para ajustar el modelo
        print(kwargs)
        if forecaster_fun.__name__ == 'forecast':
            gpttrain_y = pd.DataFrame({'y': train_y, 'ds': datos_train['ds'][:len(train_y)]})
            forecaster = forecaster_fun(df = gpttrain_y, h = len(test_y), time_col= 'ds',
            target_col= 'y', freq= 'M', level=[90], **kwargs)

            # Calculamos MAPE
            mape = mean_absolute_percentage_error(test_y, forecaster['TimeGPT'])
            mapes.append(mape)

            # Calculamos interval score
            score = interval_score(obs=test_y, lower= forecaster['TimeGPT-lo-90'], upper= forecaster['TimeGPT-hi-90'], alpha = 0.05)
            scores.append(score)

            continue


        # Luego especificamos el pronosticador
        forecaster = forecaster_fun(**kwargs)


        # Ajustamos el modelo
        try:
            forecaster.fit(train_y)
          
            # Obtenemos predicciones
            pred = forecaster.predict(num_pred)
            pred_int = forecaster.predict_interval(num_pred, coverage=0.9)

            # Calculamos MAPE
            mape = mean_absolute_percentage_error(test_y, pred)
            mapes.append(mape)

            # Calculamos Interval Score
            pred_int.columns = ['lower', 'upper']
            score = interval_score(obs=test_y, lower=pred_int['lower'], upper=pred_int['upper'], alpha = 0.05)
            scores.append(score)
        except:
            # Si el modelo falla en ajustar, asignamos NaN
            mapes.append(np.NaN)
            scores.append(np.NaN)

    # Una vez probamos todas las opciones, vemos con cual modelo se obtuvo el menor error
    if metrica == 'MAPE': 
        mejor_combinacion = mapes.index(np.nanmin(mapes))
    else :
        mejor_combinacion = scores.index(np.nanmin(scores))
        

    # Por ultimo ajustamos el mejor modelo con todo el conjunto de entrenamiento:

    kwargs = grilla.iloc[mejor_combinacion].to_dict()

    # Time GPT no necesita llamar a una funcion para ajustar el modelo

    if forecaster_fun.__name__ == 'forecast':
        timer_comienzo = time.time() # Empiezo a medir cuanto tarda en ajustar
        
        forecaster = forecaster_fun(df = datos_train, h = len(datos_test), time_col= 'ds',
            target_col= 'y', freq= 'M', level=[90], **kwargs)
        
        timer_final = time.time()
        tiempo = timer_final - timer_comienzo

        pred = forecaster['TimeGPT']
        pred_int = forecaster[['TimeGPT-lo-90', 'TimeGPT-hi-90']]
    
    else: 
        forecaster = forecaster_fun(**kwargs)
        
        timer_comienzo = time.time() # Empiezo a medir cuanto tarda en ajustar
        forecaster.fit(datos_train['y'])
            
        # Obtenemos predicciones
        fh = ForecastingHorizon(datos_test.index, is_relative=False)
        pred = forecaster.predict(fh)
        pred_int = forecaster.predict_interval(num_pred, coverage=0.9)

        timer_final = time.time()
        tiempo = timer_final - timer_comienzo

    # Agregamos a la grilla los mapes de cada combinacion
    grilla['MAPE'] = mapes
    mape_final = mean_absolute_percentage_error(datos_test['y'], pred)

    # Agregamos a la grilla los scores de cada combinacion
    grilla['Interval Scores'] = scores
    pred_int.columns = ['lower', 'upper']
    score_final = interval_score(obs=datos_test['y'], lower=pred_int['lower'], upper=pred_int['upper'], alpha = 0.05)

    if metrica == 'MAPE':
        grilla['Seleccionado'] = mapes == np.nanmin(mapes)
    else:
        grilla['Seleccionado'] = scores == np.nanmin(scores)

    # Graficamos el pronostico
    datos = pd.concat([datos_train, datos_test])
    plt.plot(datos['ds'], datos['y'])
    if forecaster_fun.__name__ == 'forecast':
        sns.lineplot(x = forecaster['ds'], y= pred, color = 'red', label = 'Prediccion')
        plt.fill_between(forecaster['ds'], pred_int['lower'], pred_int['upper'], color = 'red', alpha = 0.3, label = 'IC: 0.9')   
    else : 
        sns.lineplot(x = datos_test['ds'], y= pred, color = 'red', label = 'Prediccion')
        plt.fill_between(datos_test['ds'], pred_int['lower'], pred_int['upper'], color = 'red', alpha = 0.3, label = 'IC: 0.9')

    # Devolvemos las predicciones
    return pred, mape_final, score_final, tiempo, grilla

```

```{python}
# AUTOARIMA

parametros = {'start_p': [0], 'start_q' : [0],
    'sp':[12], 'max_p':[2], 'max_q':[2], 'd':[0,1,2], 'D':[0,1,2],  'suppress_warnings':[True]}

pred, mape, score, tiempo, resultados = tuner(forecaster_fun=AutoARIMA, parametros=parametros, datos_train=datos_train, datos_test=datos_test)

metricas.loc[len(metricas)] = ['AutoARIMA', mape, score, tiempo]
```


```{python}
# PROPHET

pred, mape, score, tiempo, resultados = tuner(forecaster_fun=Prophet, datos_train=datos_train, datos_test=datos_test)

metricas.loc[len(metricas)] = ['Prophet', mape, score, tiempo]
```


```{python}
# LSTM

# creating model instance configuring the hyperparameters

model = NeuralForecastLSTM(max_steps=200)


# fitting the model
fh = ForecastingHorizon(datos_test.index, is_relative=False)

model.fit(datos_train['y'], fh=fh)  

y_pred_lstm = model.predict()  

mape = mean_absolute_percentage_error(datos_test['y'], y_pred_lstm)

metricas.loc[len(metricas)] = ['LSTM', mape]
```

```{python}
# LightGBM y XGBoost
from xgboost import XGBRegressor
import lightgbm as lgb
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV

datos_train['month'] = datos_train['ds'].dt.month
datos_train['year'] = datos_train['ds'].dt.year
datos_test['month'] = datos_test['ds'].dt.month
datos_test['year'] = datos_test['ds'].dt.year

X_train = datos_train[['month', 'year']]
X_test = datos_test[['month', 'year']]

# XGBoost
cv_split = TimeSeriesSplit(n_splits=4)
model = XGBRegressor()
parameters = {
    "max_depth": [3, 4, 6, 5, 10],
    "learning_rate": [0.01, 0.05, 0.1, 0.2, 0.3],
    "n_estimators": [100, 300, 500, 700, 900, 1000],
    "colsample_bytree": [0.3, 0.5, 0.7]
}


grid_search = GridSearchCV(estimator=model, cv=cv_split, param_grid=parameters)
grid_search.fit(X_train, datos_train['y'])

# Prediccion
y_pred_xgb = grid_search.predict(X_test)

mape = mean_absolute_percentage_error(datos_test['y'], y_pred_xgb)

metricas.loc[len(metricas)] = ['XGBoost', mape]
```

```{python}
# LGBMoost
cv_split = TimeSeriesSplit(n_splits=3)
model = lgb.LGBMRegressor()
parameters = {
    "max_depth": [3, 4],
    "learning_rate": [0.01, 0.05, 0.1, 0.2, 0.3],
    "n_estimators": [50, 100, 300, 500, 700, 900, 1000],
    "colsample_bytree": [0.3, 0.5, 0.7]
}


grid_search = GridSearchCV(estimator=model, cv=cv_split, param_grid=parameters)
grid_search.fit(X_train, datos_train['y'])

# Prediccion
y_pred_lgb = grid_search.predict(X_test)

mape = mean_absolute_percentage_error(datos_test['y'], y_pred_lgb)

metricas.loc[len(metricas)] = ['LightGBM', mape]
```



```{python}
# Chronos

parametros = {'model_path': ['amazon/chronos-t5-tiny']}

pred, mape, tiempo, resultados = tuner(forecaster_fun=ChronosForecaster, parametros=parametros, datos_train=datos_train, datos_test=datos_test)

metricas.loc[len(metricas)] = ['Chronos', mape, tiempo]
```

```{python}
# TIME GPT

parametros = {
    'finetune_loss' : ['mape']}

pred, mape, score, tiempo, resultados = tuner(forecaster_fun=nixtla_client.forecast, parametros= parametros, datos_train=datos_train, datos_test=datos_test)

metricas.loc[len(metricas)] = ['TimeGPT', mape, score, tiempo]

```


```{python}

def is_pickleable(obj):
    """Check if an object can be pickled."""
    try:
        pickle.dumps(obj)
        return True
    except (pickle.PickleError, AttributeError, TypeError):
        return False

def save_env(filename="modelos_consumo_gas.pkl"):
    global_vars = {k: v for k, v in globals().items() if not k.startswith("__") and is_pickleable(v)}
    with open(filename, "wb") as f:
        pickle.dump(global_vars, f)

def load_env(filename="modelos_consumo_gas.pkl"):
    with open(filename, "rb") as f:
        global_vars = pickle.load(f)
        globals().update(global_vars)

# Usage
save_env()
load_env()


```